# PLT-309: Multi-Format Metadata Storage System

**Document ID**: PLT-309  
**Status**: Draft  
**Type**: Core Compiler Component  
**Author**: Prism Language Team  
**Created**: 2025-01-17  
**Last Modified**: 2025-01-17  

## Document Metadata

| Field | Value |
|-------|-------|
| **Component Area** | Metadata Export & External Integration |
| **Priority** | High |
| **Dependencies** | PLT-001 (AST Design), PLT-300 (AI Metadata Extraction), PLT-301 (Structured Export), PLD-001 (Semantic Types), PLD-003 (Effect System) |
| **Implementation Phase** | 2 |
| **Stability** | Experimental |

## Abstract

The Multi-Format Metadata Storage System provides a comprehensive, extensible approach to storing and managing metadata about Prism programs. This system generates multiple file formats optimized for different use cases: human-readable TOML for maintainability, structured JSON for AI tool integration, and binary formats for performance-critical scenarios. The design supports the full spectrum of Prism's semantic richness including effect system metadata, capability information, security classifications, and AI-comprehensible annotations while maintaining clear separation between source code (where function names live) and metadata (information about those functions).

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [File Format Specifications](#file-format-specifications)
3. [Storage Organization](#storage-organization)
4. [Metadata Generation Pipeline](#metadata-generation-pipeline)
5. [Integration Points](#integration-points)
6. [Performance Considerations](#performance-considerations)
7. [Extensibility Framework](#extensibility-framework)
8. [Implementation Details](#implementation-details)
9. [Testing Strategy](#testing-strategy)
10. [Migration and Versioning](#migration-and-versioning)

## Architecture Overview

### Design Philosophy

The Multi-Format Metadata Storage System follows Prism's core principle of **Separation of Concerns**:

- **Source Code** (`.prism` files) - Contains function names, implementations, and structure
- **Symbol Tables** (in-memory/binary cache) - Maps names to unique identifiers for resolution
- **Metadata Files** (`.prism-meta`, `.prism-ai.json`) - Contains information *about* symbols

### High-Level Architecture

```
Source Code (.prism)
        ↓
    AST + Symbols
        ↓
Semantic Analysis (PLT-300)
        ↓
Metadata Extraction Pipeline
        ↓
    ┌─────────────┬─────────────┬─────────────┐
    ↓             ↓             ↓             ↓
TOML Format   JSON Format   Binary Cache  Custom Extensions
(.prism-meta) (.prism-ai)   (.prism-bin)  (.custom)
    ↓             ↓             ↓             ↓
Human Tools   AI Tools     Performance   Specialized Tools
```

### Key Design Decisions

1. **Multiple Formats**: Each format optimized for specific use cases
2. **Reference-Based**: Metadata files reference symbols, don't define them
3. **Structured Organization**: Hierarchical directory structure for large projects
4. **Version-Aware**: Built-in versioning and migration support
5. **Extension-Friendly**: Plugin architecture for custom metadata formats

## File Format Specifications

### 1. Primary Format: TOML (`.prism-meta`)

**Purpose**: Human-readable metadata for development and maintenance

**Structure**:
```toml
[metadata]
version = "1.0"
schema = "prism-metadata-v1"
generated_at = "2025-01-17T10:30:00Z"
source_file = "secure_web_service.prism"
compiler_version = "0.1.0"

[symbols]
# Function metadata
[symbols.authenticate_user]
name = "authenticate_user"
type = "function"
visibility = "trusted_section"
effects = ["Database.Query", "Cryptography.Hashing"]
security_classification = "secret"
business_context = "user_authentication"
ai_description = "Authenticates user credentials against stored password hashes"
location = { line = 42, column = 5, span = "42:5-48:6" }

# Type metadata
[symbols.UserCredentials]
name = "UserCredentials"
type = "semantic_type"
visibility = "module"
security_classification = "secret"
business_context = "user_data"
constraints = ["username.length >= 3", "password_hash.is_valid()"]
semantic_meaning = "Represents user login credentials with security properties"

[capabilities]
[capabilities.analytics]
allowed_hosts = ["analytics.company.com"]
protocols = ["HTTPS"]
rate_limit = "10/minute"
data_restrictions = ["no_payment_data", "no_credentials"]
allowed_data_types = ["anonymized_metrics", "usage_statistics"]

[capabilities.logging]
allowed_paths = ["/var/log/app"]
operations = ["Write"]
max_file_size = "100MB"
data_restrictions = ["no_sensitive_data"]

[security_policies]
[security_policies.NoPaymentDataToAnalytics]
rule = "forall data: PaymentData { !data.flows_to(analytics) }"
enforcement = "compile_time"
violation_action = "error"
description = "Prevents payment data from flowing to analytics systems"

[security_policies.AuditSensitiveOperations]
rule = "forall operation: Operation { if operation.accesses_sensitive_data() { SecurityAudit.log(operation) } }"
enforcement = "runtime"
violation_action = "log_and_continue"

[ai_context]
module_purpose = "Secure web service with comprehensive supply chain protection"
security_properties = [
    "Dependencies cannot access user credentials",
    "Analytics cannot access payment data", 
    "Logging cannot access sensitive information"
]
business_domain = "financial_services"
compliance_requirements = ["PCI_DSS", "GDPR"]
```

### 2. AI Metadata Export Format: JSON (`.prism-ai.json`)

**Purpose**: Structured metadata optimized for AI tool consumption

```json
{
  "ai_metadata": {
    "version": "1.0",
    "schema": "prism-ai-metadata-v1",
    "generated_at": "2025-01-17T10:30:00Z",
    "source_analysis": {
      "complexity_score": 0.7,
      "security_score": 0.95,
      "maintainability_score": 0.85
    }
  },
  "symbols": {
    "authenticate_user": {
      "symbol_type": "function",
      "purpose": "User authentication with credential verification",
      "security_properties": [
        "Handles sensitive user credentials securely",
        "Uses cryptographic hashing for password verification",
        "Requires database access for user lookup",
        "Generates secure authentication tokens"
      ],
      "effects": {
        "database": {
          "operations": ["query"],
          "tables": ["users"],
          "data_types": ["password_hash", "user_id"]
        },
        "cryptography": {
          "operations": ["hashing", "token_generation"],
          "algorithms": ["SHA256", "JWT"]
        }
      },
      "business_context": {
        "domain": "authentication",
        "stakeholders": ["end_users", "security_team"],
        "compliance_impact": ["authentication_audit", "access_control"]
      },
      "ai_comprehensible_description": "This function safely authenticates users by comparing provided credentials against stored password hashes using cryptographic functions. It ensures secure access control while maintaining audit trails.",
      "code_patterns": {
        "input_validation": true,
        "error_handling": "result_type",
        "security_practices": ["no_plaintext_passwords", "secure_comparison"]
      }
    }
  },
  "data_flows": [
    {
      "from": "UserCredentials",
      "to": "Database",
      "classification": "secret",
      "purpose": "authentication_lookup",
      "safeguards": ["encrypted_connection", "parameterized_query"]
    },
    {
      "from": "PaymentData", 
      "to": "PaymentGateway",
      "classification": "top_secret",
      "purpose": "payment_processing",
      "safeguards": ["end_to_end_encryption", "capability_restricted"]
    }
  ],
  "security_analysis": {
    "threat_model": {
      "assets": ["user_credentials", "payment_data", "authentication_tokens"],
      "threats": ["credential_theft", "payment_fraud", "session_hijacking"],
      "mitigations": ["capability_isolation", "effect_tracking", "audit_logging"]
    },
    "capability_analysis": {
      "analytics": {
        "risk_level": "low",
        "restrictions": ["no_pii", "no_payment_data"],
        "monitoring": ["data_flow_tracking", "access_auditing"]
      },
      "logging": {
        "risk_level": "medium", 
        "restrictions": ["no_sensitive_data", "local_only"],
        "monitoring": ["log_content_scanning"]
      }
    }
  },
  "business_intelligence": {
    "domain_concepts": ["user_management", "payment_processing", "security_enforcement"],
    "process_flows": ["user_registration", "authentication", "payment_processing"],
    "compliance_mappings": {
      "PCI_DSS": ["payment_data_protection", "access_control", "audit_logging"],
      "GDPR": ["data_minimization", "consent_management", "data_portability"]
    }
  }
}
```

### 3. Binary Cache Format (`.prism-bin`)

**Purpose**: High-performance metadata loading for compilation

```rust
// Binary format specification
#[derive(Serialize, Deserialize)]
pub struct BinaryMetadata {
    pub header: BinaryHeader,
    pub symbol_table: CompressedSymbolTable,
    pub type_information: CompressedTypeInfo,
    pub effect_signatures: CompressedEffectInfo,
    pub capability_graph: CompressedCapabilityGraph,
}

#[derive(Serialize, Deserialize)]
pub struct BinaryHeader {
    pub magic: [u8; 4], // "PRMD"
    pub version: u32,
    pub checksum: u64,
    pub compression: CompressionType,
    pub metadata_size: u64,
}
```

## Storage Organization

### Project Structure

```
project/
├── src/
│   ├── secure_web_service.prism           # Source code
│   ├── payment_processor.prism
│   └── user_management.prism
├── .prism/                                # Metadata directory
│   ├── metadata/                          # Primary metadata
│   │   ├── secure_web_service.prism-meta
│   │   ├── payment_processor.prism-meta
│   │   └── user_management.prism-meta
│   ├── ai/                                # AI-optimized metadata
│   │   ├── secure_web_service.prism-ai.json
│   │   ├── payment_processor.prism-ai.json
│   │   └── user_management.prism-ai.json
│   ├── cache/                             # Binary cache
│   │   ├── secure_web_service.prism-bin
│   │   └── metadata_index.bin
│   ├── capabilities/                      # Capability definitions
│   │   ├── analytics.toml
│   │   ├── logging.toml
│   │   └── payment_gateway.toml
│   ├── policies/                          # Security policies
│   │   ├── information_flow.toml
│   │   ├── capability_restrictions.toml
│   │   └── audit_requirements.toml
│   └── config/                           # System configuration
│       ├── metadata_config.toml
│       └── export_settings.toml
```

### Large Project Organization

```
enterprise_project/
├── .prism/
│   ├── metadata/
│   │   ├── modules/
│   │   │   ├── auth/
│   │   │   ├── payment/
│   │   │   └── analytics/
│   │   └── global/
│   │       ├── shared_types.prism-meta
│   │       └── global_policies.prism-meta
│   ├── shards/                           # Sharded metadata for performance
│   │   ├── shard_0000.prism-bin
│   │   ├── shard_0001.prism-bin
│   │   └── shard_index.bin
│   └── indexes/                          # Search indexes
│       ├── symbol_index.bin
│       ├── type_index.bin
│       └── effect_index.bin
```

## Metadata Generation Pipeline

### Generation Workflow

```rust
pub struct MetadataGenerator {
    config: GenerationConfig,
    extractors: Vec<Box<dyn MetadataExtractor>>,
    formatters: HashMap<String, Box<dyn MetadataFormatter>>,
    validators: Vec<Box<dyn MetadataValidator>>,
}

impl MetadataGenerator {
    pub async fn generate_metadata(&mut self, program: &Program) -> Result<GeneratedMetadata> {
        // Phase 1: Extract metadata from AST and semantic analysis
        let raw_metadata = self.extract_metadata(program).await?;
        
        // Phase 2: Validate metadata consistency
        self.validate_metadata(&raw_metadata)?;
        
        // Phase 3: Generate all requested formats
        let mut outputs = HashMap::new();
        
        if self.config.generate_toml {
            let toml_output = self.formatters["toml"].format(&raw_metadata)?;
            outputs.insert("toml".to_string(), toml_output);
        }
        
        if self.config.generate_ai_json {
            let json_output = self.formatters["ai_json"].format(&raw_metadata)?;
            outputs.insert("ai_json".to_string(), json_output);
        }
        
        if self.config.generate_binary {
            let binary_output = self.formatters["binary"].format(&raw_metadata)?;
            outputs.insert("binary".to_string(), binary_output);
        }
        
        // Phase 4: Write outputs to appropriate locations
        self.write_outputs(&outputs).await?;
        
        Ok(GeneratedMetadata { outputs })
    }
}
```

### Metadata Extraction

```rust
pub trait MetadataExtractor: Send + Sync {
    fn extract(&self, program: &Program) -> Result<ExtractedMetadata>;
    fn supports_incremental(&self) -> bool { false }
}

pub struct SymbolMetadataExtractor;
impl MetadataExtractor for SymbolMetadataExtractor {
    fn extract(&self, program: &Program) -> Result<ExtractedMetadata> {
        let mut symbols = HashMap::new();
        
        for item in &program.items {
            match &item.kind {
                Item::Function(func) => {
                    let metadata = FunctionMetadata {
                        name: func.name.resolve().unwrap(),
                        effects: extract_effects(func)?,
                        security_classification: infer_security_level(func)?,
                        business_context: infer_business_context(&func.name)?,
                        ai_description: generate_ai_description(func)?,
                    };
                    symbols.insert(func.name, SymbolMetadata::Function(metadata));
                }
                // Handle other item types...
            }
        }
        
        Ok(ExtractedMetadata { symbols, ..Default::default() })
    }
}
```

## Integration Points

### 1. Compiler Integration

```rust
// In prism-compiler/src/compilation_pipeline.rs
impl CompilationPipeline {
    pub async fn compile_with_metadata(&mut self, source: &Path) -> CompilerResult<CompilationOutput> {
        // Normal compilation phases
        let program = self.parse(source).await?;
        let semantic_info = self.analyze_semantics(&program).await?;
        
        // Generate metadata if enabled
        if self.config.generate_metadata {
            let metadata = self.metadata_generator
                .generate_metadata(&program)
                .await?;
            
            // Store metadata for later use
            self.metadata_cache.store(source, metadata)?;
        }
        
        let codegen_output = self.generate_code(&program, &semantic_info).await?;
        
        Ok(CompilationOutput {
            program,
            semantic_info,
            generated_code: codegen_output,
            metadata_generated: self.config.generate_metadata,
        })
    }
}
```

### 2. IDE Integration

```rust
// Language server protocol integration
pub struct PrismLanguageServer {
    metadata_cache: MetadataCache,
}

impl PrismLanguageServer {
    pub fn get_hover_info(&self, position: Position) -> Option<HoverInfo> {
        let metadata = self.metadata_cache.get_metadata_at_position(position)?;
        
        Some(HoverInfo {
            contents: metadata.ai_description.clone(),
            security_info: metadata.security_classification,
            effects: metadata.effects.clone(),
            business_context: metadata.business_context.clone(),
        })
    }
}
```

### 3. AI Tool Integration

```rust
// External AI tool API
pub struct AIMetadataAPI {
    metadata_store: MetadataStore,
}

impl AIMetadataAPI {
    pub async fn get_function_context(&self, function_name: &str) -> Result<AIFunctionContext> {
        let metadata = self.metadata_store
            .load_ai_metadata(function_name)
            .await?;
            
        Ok(AIFunctionContext {
            purpose: metadata.purpose,
            security_properties: metadata.security_properties,
            business_context: metadata.business_context,
            code_patterns: metadata.code_patterns,
            compliance_info: metadata.compliance_mappings,
        })
    }
}
```

## Performance Considerations

### 1. Generation Performance

- **Incremental Generation**: Only regenerate metadata for changed files
- **Parallel Processing**: Generate different formats concurrently
- **Caching**: Cache intermediate results between compilations
- **Lazy Loading**: Load metadata on-demand rather than eagerly

### 2. Storage Performance

- **Binary Format**: Fast serialization/deserialization for compilation
- **Compression**: LZ4 compression for binary metadata
- **Indexing**: B-tree indexes for fast symbol lookup
- **Sharding**: Split large metadata sets across multiple files

### 3. Memory Management

```rust
pub struct MetadataCache {
    hot_cache: LruCache<PathBuf, Arc<Metadata>>,
    cold_storage: DiskBackedCache,
    memory_limit: usize,
}

impl MetadataCache {
    pub fn get_metadata(&mut self, path: &Path) -> Result<Arc<Metadata>> {
        // Check hot cache first
        if let Some(metadata) = self.hot_cache.get(path) {
            return Ok(metadata.clone());
        }
        
        // Load from cold storage
        let metadata = Arc::new(self.cold_storage.load(path)?);
        
        // Manage memory usage
        if self.memory_usage() > self.memory_limit {
            self.evict_cold_entries();
        }
        
        self.hot_cache.put(path.to_path_buf(), metadata.clone());
        Ok(metadata)
    }
}
```

## Extensibility Framework

### Custom Format Plugins

```rust
pub trait MetadataFormatter: Send + Sync {
    fn format_name(&self) -> &str;
    fn file_extension(&self) -> &str;
    fn format(&self, metadata: &ExtractedMetadata) -> Result<Vec<u8>>;
    fn supports_incremental(&self) -> bool { false }
}

// Example custom formatter
pub struct GraphQLSchemaFormatter;
impl MetadataFormatter for GraphQLSchemaFormatter {
    fn format_name(&self) -> &str { "graphql_schema" }
    fn file_extension(&self) -> &str { ".graphql" }
    
    fn format(&self, metadata: &ExtractedMetadata) -> Result<Vec<u8>> {
        let mut schema = String::new();
        
        for (symbol, info) in &metadata.symbols {
            if let SymbolMetadata::Function(func) = info {
                schema.push_str(&format!(
                    "type Query {{ {}: {} }}\n",
                    func.name,
                    infer_graphql_type(&func.return_type)
                ));
            }
        }
        
        Ok(schema.into_bytes())
    }
}
```

### Configuration System

```toml
# .prism/config/metadata_config.toml
[generation]
enabled = true
incremental = true
formats = ["toml", "ai_json", "binary"]

[formats.toml]
enabled = true
include_source_locations = true
include_ai_descriptions = true
compression = false

[formats.ai_json]
enabled = true
include_business_context = true
include_security_analysis = true
include_compliance_mappings = true
compression = true

[formats.binary]
enabled = true
compression = "lz4"
sharding_threshold = "10MB"

[custom_formats]
graphql_schema = { enabled = true, output_dir = "schema/" }
openapi_spec = { enabled = false }

[performance]
max_memory = "1GB"
parallel_generation = true
cache_ttl = "1h"
```

## Implementation Details

### Phase 1: Core Infrastructure (Month 1)

1. **Basic TOML Generation**
   - Implement `TomlMetadataFormatter`
   - Basic symbol metadata extraction
   - File I/O infrastructure

2. **Storage Organization**
   - Create `.prism/` directory structure
   - Implement metadata file management
   - Basic configuration system

### Phase 2: Metadata Export (Month 2)

1. **JSON Format Support**
   - Implement `AIJsonMetadataFormatter`
   - Rich AI metadata generation
   - Business context extraction

2. **Integration APIs**
   - External tool API endpoints
   - Language server integration
   - IDE plugin support

### Phase 3: Performance Optimization (Month 3)

1. **Binary Format**
   - Implement `BinaryMetadataFormatter`
   - Compression and indexing
   - Incremental updates

2. **Caching System**
   - Memory-efficient caching
   - Disk-backed storage
   - Performance monitoring

### Phase 4: Advanced Features (Month 4)

1. **Extensibility**
   - Plugin system for custom formats
   - Configuration validation
   - Migration tools

2. **Enterprise Features**
   - Sharding for large projects
   - Distributed metadata storage
   - Advanced security features

## Testing Strategy

### Unit Tests

```rust
#[cfg(test)]
mod tests {
    use super::*;
    
    #[test]
    fn test_toml_generation() {
        let program = parse_test_program(r#"
            function authenticate_user(creds: UserCredentials) -> AuthResult {
                // implementation
            }
        "#);
        
        let extractor = SymbolMetadataExtractor;
        let metadata = extractor.extract(&program).unwrap();
        
        let formatter = TomlMetadataFormatter::new();
        let output = formatter.format(&metadata).unwrap();
        
        let parsed: toml::Value = toml::from_slice(&output).unwrap();
        assert!(parsed["symbols"]["authenticate_user"]["name"] == "authenticate_user");
    }
    
    #[test]
    fn test_ai_json_generation() {
        // Similar test for AI JSON format
    }
    
    #[test] 
    fn test_binary_roundtrip() {
        // Test binary serialization/deserialization
    }
}
```

### Integration Tests

```rust
#[tokio::test]
async fn test_full_metadata_pipeline() {
    let temp_dir = TempDir::new().unwrap();
    let source_file = temp_dir.path().join("test.prism");
    
    std::fs::write(&source_file, TEST_PROGRAM).unwrap();
    
    let mut generator = MetadataGenerator::new(GenerationConfig::default());
    let program = parse_program(&source_file).await.unwrap();
    let metadata = generator.generate_metadata(&program).await.unwrap();
    
    // Verify all formats were generated
    assert!(temp_dir.path().join(".prism/metadata/test.prism-meta").exists());
    assert!(temp_dir.path().join(".prism/ai/test.prism-ai.json").exists());
    assert!(temp_dir.path().join(".prism/cache/test.prism-bin").exists());
    
    // Verify content correctness
    let toml_content = std::fs::read_to_string(
        temp_dir.path().join(".prism/metadata/test.prism-meta")
    ).unwrap();
    
    let parsed: toml::Value = toml::from_str(&toml_content).unwrap();
    assert!(parsed["symbols"]["test_function"]["type"] == "function");
}
```

### Performance Tests

```rust
#[bench]
fn bench_metadata_generation(b: &mut Bencher) {
    let large_program = generate_large_test_program(1000); // 1000 functions
    let mut generator = MetadataGenerator::new(GenerationConfig::default());
    
    b.iter(|| {
        black_box(generator.generate_metadata(&large_program))
    });
}

#[bench]
fn bench_binary_loading(b: &mut Bencher) {
    let binary_metadata = create_test_binary_metadata();
    
    b.iter(|| {
        black_box(BinaryMetadata::deserialize(&binary_metadata))
    });
}
```

## Migration and Versioning

### Version Management

```rust
#[derive(Debug, Clone)]
pub struct MetadataVersion {
    pub major: u32,
    pub minor: u32, 
    pub patch: u32,
}

impl MetadataVersion {
    pub fn is_compatible(&self, other: &MetadataVersion) -> bool {
        self.major == other.major && self.minor <= other.minor
    }
}

pub struct MetadataMigrator {
    migrations: HashMap<(MetadataVersion, MetadataVersion), Box<dyn Migration>>,
}

pub trait Migration: Send + Sync {
    fn migrate(&self, old_metadata: &[u8]) -> Result<Vec<u8>>;
    fn is_reversible(&self) -> bool { false }
    fn reverse(&self, new_metadata: &[u8]) -> Result<Vec<u8>> {
        Err(anyhow::anyhow!("Migration is not reversible"))
    }
}
```

### Schema Evolution

```toml
# Migration configuration
[migrations]
auto_migrate = true
backup_before_migration = true
max_backup_age = "30d"

[[migrations.rules]]
from_version = "1.0"
to_version = "1.1"
changes = [
    "add_field:symbols.*.security_classification",
    "rename_field:symbols.*.ai_hints->ai_description"
]

[[migrations.rules]]
from_version = "1.1"
to_version = "2.0"
breaking = true
changes = [
    "restructure:capabilities->security.capabilities",
    "remove_field:symbols.*.deprecated_field"
]
```

This comprehensive PLT-309 document provides a complete technical specification for the multi-format metadata storage system we discussed. It covers all the key aspects:

- **Clear separation** between source code (function names) and metadata (information about functions)
- **Multiple formats** optimized for different use cases
- **Extensible architecture** for custom formats and analyzers
- **Performance considerations** for large projects
- **Integration points** with the compiler, IDE, and AI tools
- **Comprehensive testing strategy**
- **Migration and versioning** support

The document is now properly indexed in the PLT system as PLT-309 and ready for implementation! 