# PLT-009: Error Reporting & Diagnostics

**Document ID**: PLT-009  
**Status**: Draft  
**Type**: Core Compiler Component  
**Author**: Prism Language Team  
**Created**: 2025-01-17  
**Last Modified**: 2025-01-17  

## Document Metadata

| Field | Value |
|-------|-------|
| **Component Area** | Compiler Frontend |
| **Priority** | High |
| **Dependencies** | PLT-001 (AST Design), PLT-002 (Lexical Analysis), PLT-003 (Parsing Strategies), PLT-004 (Symbol Table), PLT-005 (Type Checking), PLT-006 (Query Architecture), PLD-001 (Semantic Types), PLD-002 (Smart Modules), PLD-003 (Effect System) |
| **Implementation Phase** | 1 |
| **Stability** | Experimental |

## Abstract

The Error Reporting & Diagnostics system implements Prism's comprehensive approach to compiler feedback, integrating with all language subsystems to provide contextual, actionable, and AI-comprehensible error reporting. Building upon the existing diagnostic infrastructure in `prism-common`, this system transforms traditional compiler errors into structured, semantic-aware diagnostics that guide developers toward correct solutions while generating rich metadata for AI analysis. The design draws inspiration from Rust's excellent error messages, TypeScript's contextual diagnostics, and Elm's helpful compiler guidance, while introducing novel AI-first features like semantic context extraction, business rule validation, and conceptual cohesion analysis.

## Table of Contents

1. [Architecture Overview](#architecture-overview)
2. [Diagnostic System Design](#diagnostic-system-design)
3. [Contextual Error Analysis](#contextual-error-analysis)
4. [AI-First Diagnostic Metadata](#ai-first-diagnostic-metadata)
5. [Multi-Phase Error Integration](#multi-phase-error-integration)
6. [Implementation Details](#implementation-details)
7. [Performance Considerations](#performance-considerations)
8. [Testing Strategy](#testing-strategy)
9. [Integration Points](#integration-points)
10. [Open Issues](#open-issues)
11. [References](#references)
12. [Appendices](#appendices)

## Architecture Overview

### High-Level Design Philosophy

The Prism diagnostic system embodies the principle that **"errors are teaching moments, not roadblocks."** Every diagnostic serves three audiences:

1. **Human Developers**: Clear, actionable guidance with context-appropriate suggestions
2. **AI Systems**: Structured metadata for automated analysis and code generation
3. **Development Tools**: Rich information for IDE integration and automated fixes

### Integration with Compiler Pipeline

The diagnostic system integrates deeply with every compiler phase:

```
Source Code (Multi-Syntax)
     ↓
Lexical Analysis (PLT-002) → Lexical Diagnostics
     ↓
Parsing (PLT-003) → Syntax Diagnostics + Error Recovery
     ↓
Symbol Resolution (PLT-004) → Scope Diagnostics
     ↓
Type Checking (PLT-005) → Semantic Diagnostics
     ↓
Effect Analysis (PLD-003) → Capability Diagnostics
     ↓
Cohesion Analysis (PLD-002) → Architecture Diagnostics
     ↓
AI Metadata Export → Structured Diagnostic Metadata
```

### Key Design Decisions

1. **Semantic Context Preservation**: Every diagnostic includes business and semantic context
2. **Multi-Level Suggestions**: From quick fixes to architectural improvements
3. **AI-Readable Structure**: All diagnostics generate structured metadata
4. **Progressive Disclosure**: Simple errors show basic info, complex ones show detailed analysis
5. **Cross-Phase Integration**: Diagnostics can combine information from multiple compiler phases
6. **Recovery-Aware**: Diagnostics understand and explain error recovery attempts

## Diagnostic System Design

### 1. Enhanced Diagnostic Architecture

Building upon `prism-common::diagnostics`, we extend the system with semantic awareness:

```rust
/// Enhanced diagnostic with semantic context and AI metadata
#[derive(Debug, Clone)]
pub struct PrismDiagnostic {
    /// Base diagnostic information
    pub base: prism_common::diagnostics::Diagnostic,
    
    /// Semantic context for this diagnostic
    pub semantic_context: Option<SemanticContext>,
    
    /// Business domain context
    pub business_context: Option<BusinessContext>,
    
    /// Effect system context
    pub effect_context: Option<EffectContext>,
    
    /// Module cohesion context
    pub cohesion_context: Option<CohesionContext>,
    
    /// AI-comprehensible metadata
    pub ai_metadata: DiagnosticAIMetadata,
    
    /// Related diagnostics that provide additional context
    pub related_diagnostics: Vec<RelatedDiagnostic>,
    
    /// Suggested fixes with confidence levels
    pub suggested_fixes: Vec<SuggestedFix>,
    
    /// Educational content for learning
    pub educational_content: Option<EducationalContent>,
}

/// Semantic context for diagnostics
#[derive(Debug, Clone)]
pub struct SemanticContext {
    /// The semantic type involved in the error
    pub semantic_type: Option<SemanticType>,
    
    /// Business meaning of the construct
    pub business_meaning: Option<String>,
    
    /// Domain-specific constraints
    pub domain_constraints: Vec<DomainConstraint>,
    
    /// Type relationships that led to the error
    pub type_relationships: Vec<TypeRelationship>,
}

/// Business context for diagnostics
#[derive(Debug, Clone)]
pub struct BusinessContext {
    /// Business capability being implemented
    pub capability: Option<String>,
    
    /// Business rules that apply
    pub applicable_rules: Vec<BusinessRule>,
    
    /// Compliance requirements
    pub compliance_requirements: Vec<ComplianceRequirement>,
    
    /// Architectural patterns in use
    pub architectural_patterns: Vec<ArchitecturalPattern>,
}

/// Effect system context for diagnostics
#[derive(Debug, Clone)]
pub struct EffectContext {
    /// Required capabilities for the operation
    pub required_capabilities: Vec<Capability>,
    
    /// Available capabilities in current scope
    pub available_capabilities: Vec<Capability>,
    
    /// Effect that caused the error
    pub violating_effect: Option<Effect>,
    
    /// Capability derivation suggestions
    pub capability_suggestions: Vec<CapabilitySuggestion>,
}

/// Module cohesion context for diagnostics
#[derive(Debug, Clone)]
pub struct CohesionContext {
    /// Current module cohesion score
    pub cohesion_score: f64,
    
    /// Cohesion threshold that was violated
    pub threshold: Option<f64>,
    
    /// Specific cohesion violations
    pub violations: Vec<CohesionViolation>,
    
    /// Suggested module restructuring
    pub restructuring_suggestions: Vec<RestructuringSuggestion>,
}

/// AI-comprehensible metadata for diagnostics
#[derive(Debug, Clone)]
pub struct DiagnosticAIMetadata {
    /// Category of error for AI classification
    pub error_category: ErrorCategory,
    
    /// Confidence level in the diagnostic
    pub confidence: f64,
    
    /// Structured error pattern
    pub error_pattern: ErrorPattern,
    
    /// Code elements involved in the error
    pub involved_elements: Vec<CodeElement>,
    
    /// Suggested learning resources
    pub learning_resources: Vec<LearningResource>,
    
    /// Automation potential for fixing this error
    pub automation_potential: AutomationPotential,
}
```

### 2. Diagnostic Categories and Classification

**Inspired by**: Rust's error codes, TypeScript's error categories, and Elm's error classification

```rust
/// Hierarchical error categorization for AI analysis
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ErrorCategory {
    /// Lexical and syntax errors
    Syntax {
        subcategory: SyntaxErrorSubcategory,
        syntax_style: Option<SyntaxStyle>,
        recovery_attempted: bool,
    },
    
    /// Type system errors
    Type {
        subcategory: TypeErrorSubcategory,
        semantic_level: SemanticLevel,
        business_impact: BusinessImpact,
    },
    
    /// Semantic analysis errors
    Semantic {
        subcategory: SemanticErrorSubcategory,
        domain_context: Option<String>,
        constraint_type: ConstraintType,
    },
    
    /// Effect system and capability errors
    Effect {
        subcategory: EffectErrorSubcategory,
        capability_type: CapabilityType,
        security_level: SecurityLevel,
    },
    
    /// Module organization and cohesion errors
    Architecture {
        subcategory: ArchitectureErrorSubcategory,
        cohesion_impact: CohesionImpact,
        refactoring_complexity: RefactoringComplexity,
    },
    
    /// Documentation and annotation errors (PSG-003)
    Documentation {
        subcategory: DocumentationErrorSubcategory,
        required_level: DocumentationLevel,
        ai_impact: AIComprehensionImpact,
    },
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum SyntaxErrorSubcategory {
    UnexpectedToken,
    MissingDelimiter,
    InvalidStructure,
    MultiSyntaxConflict,
    RecoveryFailure,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum TypeErrorSubcategory {
    Mismatch,
    MissingAnnotation,
    InvalidConstraint,
    SemanticViolation,
    BusinessRuleViolation,
    CircularDependency,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum SemanticErrorSubcategory {
    UndefinedSymbol,
    ScopeViolation,
    VisibilityViolation,
    ContractViolation,
    InvariantViolation,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum EffectErrorSubcategory {
    MissingCapability,
    UnauthorizedEffect,
    CapabilityConflict,
    SecurityViolation,
    ResourceViolation,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ArchitectureErrorSubcategory {
    CohesionViolation,
    ResponsibilityViolation,
    LayerViolation,
    DependencyViolation,
    ModularityViolation,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum DocumentationErrorSubcategory {
    MissingRequired,
    InconsistentImplementation,
    InvalidAnnotation,
    InsufficientDetail,
    AIComprehensionIssue,
}
```

### 3. Contextual Error Analysis Engine

**Inspired by**: Rust's trait solver diagnostics and TypeScript's contextual analysis

```rust
/// Engine for analyzing error context and generating rich diagnostics
pub struct ContextualErrorAnalyzer {
    /// Symbol table for scope analysis
    symbol_table: Arc<SymbolTable>,
    
    /// Type checker for semantic analysis
    type_checker: Arc<TypeChecker>,
    
    /// Effect analyzer for capability analysis
    effect_analyzer: Arc<EffectAnalyzer>,
    
    /// Cohesion analyzer for architectural analysis
    cohesion_analyzer: Arc<CohesionAnalyzer>,
    
    /// AI metadata extractor
    ai_extractor: Arc<AIMetadataExtractor>,
    
    /// Historical error database for pattern analysis
    error_history: Arc<ErrorHistoryDatabase>,
}

impl ContextualErrorAnalyzer {
    /// Analyze an error and generate comprehensive diagnostic
    pub fn analyze_error(
        &self,
        error: &CompilerError,
        source_context: &SourceContext,
    ) -> Result<PrismDiagnostic, AnalysisError> {
        // Start with base diagnostic
        let base_diagnostic = self.create_base_diagnostic(error)?;
        
        // Analyze semantic context
        let semantic_context = self.analyze_semantic_context(error, source_context)?;
        
        // Analyze business context
        let business_context = self.analyze_business_context(error, source_context)?;
        
        // Analyze effect context
        let effect_context = self.analyze_effect_context(error, source_context)?;
        
        // Analyze cohesion context
        let cohesion_context = self.analyze_cohesion_context(error, source_context)?;
        
        // Generate AI metadata
        let ai_metadata = self.generate_ai_metadata(error, source_context)?;
        
        // Find related diagnostics
        let related_diagnostics = self.find_related_diagnostics(error, source_context)?;
        
        // Generate suggested fixes
        let suggested_fixes = self.generate_suggested_fixes(
            error,
            source_context,
            &semantic_context,
            &business_context,
            &effect_context,
        )?;
        
        // Generate educational content
        let educational_content = self.generate_educational_content(error, &ai_metadata)?;
        
        Ok(PrismDiagnostic {
            base: base_diagnostic,
            semantic_context,
            business_context,
            effect_context,
            cohesion_context,
            ai_metadata,
            related_diagnostics,
            suggested_fixes,
            educational_content,
        })
    }
    
    /// Analyze semantic context for an error
    fn analyze_semantic_context(
        &self,
        error: &CompilerError,
        context: &SourceContext,
    ) -> Result<Option<SemanticContext>, AnalysisError> {
        match error {
            CompilerError::Type { expected, found, span, .. } => {
                let semantic_type = self.type_checker.get_semantic_type_at(*span)?;
                let business_meaning = self.extract_business_meaning(semantic_type.as_ref())?;
                let domain_constraints = self.get_applicable_constraints(*span)?;
                let type_relationships = self.analyze_type_relationships(expected, found)?;
                
                Ok(Some(SemanticContext {
                    semantic_type,
                    business_meaning,
                    domain_constraints,
                    type_relationships,
                }))
            }
            CompilerError::Semantic { constraint, span, .. } => {
                let semantic_type = self.type_checker.get_semantic_type_at(*span)?;
                let business_meaning = self.extract_business_meaning(semantic_type.as_ref())?;
                let domain_constraints = vec![constraint.clone()];
                
                Ok(Some(SemanticContext {
                    semantic_type,
                    business_meaning,
                    domain_constraints,
                    type_relationships: Vec::new(),
                }))
            }
            _ => Ok(None),
        }
    }
    
    /// Analyze business context for an error
    fn analyze_business_context(
        &self,
        error: &CompilerError,
        context: &SourceContext,
    ) -> Result<Option<BusinessContext>, AnalysisError> {
        // Get the current module and its business capability
        let current_module = self.symbol_table.get_containing_module(context.span)?;
        let capability = current_module.and_then(|m| m.business_capability.clone());
        
        // Get applicable business rules
        let applicable_rules = self.get_applicable_business_rules(context.span)?;
        
        // Get compliance requirements
        let compliance_requirements = self.get_compliance_requirements(context.span)?;
        
        // Detect architectural patterns
        let architectural_patterns = self.detect_architectural_patterns(context)?;
        
        if capability.is_some() || !applicable_rules.is_empty() || 
           !compliance_requirements.is_empty() || !architectural_patterns.is_empty() {
            Ok(Some(BusinessContext {
                capability,
                applicable_rules,
                compliance_requirements,
                architectural_patterns,
            }))
        } else {
            Ok(None)
        }
    }
    
    /// Generate suggested fixes with confidence levels
    fn generate_suggested_fixes(
        &self,
        error: &CompilerError,
        context: &SourceContext,
        semantic_context: &Option<SemanticContext>,
        business_context: &Option<BusinessContext>,
        effect_context: &Option<EffectContext>,
    ) -> Result<Vec<SuggestedFix>, AnalysisError> {
        let mut fixes = Vec::new();
        
        match error {
            CompilerError::Type { expected, found, span, .. } => {
                // Type coercion fix
                if let Some(coercion) = self.suggest_type_coercion(expected, found, *span)? {
                    fixes.push(SuggestedFix {
                        description: format!("Convert {} to {}", found, expected),
                        confidence: coercion.confidence,
                        fix_type: FixType::TypeCoercion,
                        code_changes: coercion.code_changes,
                        explanation: coercion.explanation,
                        ai_reasoning: coercion.ai_reasoning,
                    });
                }
                
                // Semantic type annotation fix
                if let Some(semantic_context) = semantic_context {
                    if let Some(annotation_fix) = self.suggest_semantic_annotation(
                        semantic_context,
                        *span
                    )? {
                        fixes.push(annotation_fix);
                    }
                }
                
                // Business rule compliance fix
                if let Some(business_context) = business_context {
                    for rule in &business_context.applicable_rules {
                        if let Some(compliance_fix) = self.suggest_business_rule_compliance(
                            rule,
                            expected,
                            found,
                            *span
                        )? {
                            fixes.push(compliance_fix);
                        }
                    }
                }
            }
            
            CompilerError::Effect { missing_capability, effect, span, .. } => {
                // Capability acquisition fix
                if let Some(acquisition_fix) = self.suggest_capability_acquisition(
                    missing_capability,
                    effect,
                    *span
                )? {
                    fixes.push(acquisition_fix);
                }
                
                // Effect removal fix
                if let Some(removal_fix) = self.suggest_effect_removal(effect, *span)? {
                    fixes.push(removal_fix);
                }
                
                // Alternative implementation fix
                if let Some(alternative_fix) = self.suggest_alternative_implementation(
                    missing_capability,
                    effect,
                    *span
                )? {
                    fixes.push(alternative_fix);
                }
            }
            
            CompilerError::Architecture { cohesion_score, threshold, violations, span, .. } => {
                // Module restructuring fixes
                for violation in violations {
                    if let Some(restructuring_fix) = self.suggest_module_restructuring(
                        violation,
                        *cohesion_score,
                        *threshold,
                        *span
                    )? {
                        fixes.push(restructuring_fix);
                    }
                }
                
                // Responsibility separation fix
                if let Some(separation_fix) = self.suggest_responsibility_separation(
                    violations,
                    *span
                )? {
                    fixes.push(separation_fix);
                }
            }
            
            _ => {}
        }
        
        // Sort fixes by confidence level
        fixes.sort_by(|a, b| b.confidence.partial_cmp(&a.confidence).unwrap_or(std::cmp::Ordering::Equal));
        
        Ok(fixes)
    }
}

/// A suggested fix with confidence and reasoning
#[derive(Debug, Clone)]
pub struct SuggestedFix {
    /// Human-readable description of the fix
    pub description: String,
    
    /// Confidence level (0.0 to 1.0)
    pub confidence: f64,
    
    /// Type of fix being suggested
    pub fix_type: FixType,
    
    /// Specific code changes to apply
    pub code_changes: Vec<CodeChange>,
    
    /// Explanation of why this fix works
    pub explanation: String,
    
    /// AI reasoning behind the suggestion
    pub ai_reasoning: Option<AIReasoning>,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum FixType {
    /// Quick syntax fix
    SyntaxFix,
    
    /// Type annotation or coercion
    TypeCoercion,
    
    /// Semantic type enhancement
    SemanticAnnotation,
    
    /// Capability acquisition
    CapabilityAcquisition,
    
    /// Effect modification
    EffectModification,
    
    /// Module restructuring
    ModuleRestructuring,
    
    /// Documentation addition
    DocumentationEnhancement,
    
    /// Business rule compliance
    BusinessRuleCompliance,
}

/// Specific code change within a suggested fix
#[derive(Debug, Clone)]
pub struct CodeChange {
    /// Span to modify
    pub span: Span,
    
    /// New text to insert
    pub new_text: String,
    
    /// Type of change
    pub change_type: ChangeType,
    
    /// Additional context for the change
    pub context: Option<String>,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ChangeType {
    Replace,
    Insert,
    Delete,
    Reorder,
}
```

## AI-First Diagnostic Metadata

### 1. Structured Metadata Export

**Inspired by**: Language Server Protocol, enhanced for AI comprehension

```rust
/// AI-comprehensible diagnostic metadata
pub struct DiagnosticAIExport {
    /// Core diagnostic information
    pub diagnostic_info: DiagnosticInfo,
    
    /// Semantic analysis results
    pub semantic_analysis: SemanticAnalysis,
    
    /// Business context extraction
    pub business_context: BusinessContextAnalysis,
    
    /// Code quality metrics
    pub quality_metrics: QualityMetrics,
    
    /// Learning opportunities
    pub learning_opportunities: Vec<LearningOpportunity>,
    
    /// Automation suggestions
    pub automation_suggestions: Vec<AutomationSuggestion>,
}

/// Core diagnostic information for AI
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DiagnosticInfo {
    /// Unique error identifier
    pub error_id: String,
    
    /// Error category and classification
    pub category: ErrorCategory,
    
    /// Severity level
    pub severity: Severity,
    
    /// Source location
    pub location: LocationInfo,
    
    /// Error message and description
    pub message: MessageInfo,
    
    /// Recovery information
    pub recovery_info: Option<RecoveryInfo>,
}

/// Semantic analysis for AI consumption
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SemanticAnalysis {
    /// Types involved in the error
    pub type_information: Vec<TypeInfo>,
    
    /// Semantic relationships
    pub semantic_relationships: Vec<SemanticRelationship>,
    
    /// Domain constraints
    pub domain_constraints: Vec<ConstraintInfo>,
    
    /// Business rules
    pub business_rules: Vec<BusinessRuleInfo>,
    
    /// Effect information
    pub effects: Vec<EffectInfo>,
}

/// Business context analysis for AI
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct BusinessContextAnalysis {
    /// Business capability context
    pub capability_context: Option<CapabilityContext>,
    
    /// Domain modeling context
    pub domain_context: Option<DomainContext>,
    
    /// Architectural context
    pub architectural_context: Option<ArchitecturalContext>,
    
    /// Compliance context
    pub compliance_context: Option<ComplianceContext>,
}

/// Code quality metrics for AI analysis
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct QualityMetrics {
    /// Conceptual cohesion score
    pub cohesion_score: f64,
    
    /// Complexity metrics
    pub complexity_metrics: ComplexityMetrics,
    
    /// Maintainability score
    pub maintainability_score: f64,
    
    /// Readability score
    pub readability_score: f64,
    
    /// AI comprehensibility score
    pub ai_comprehensibility_score: f64,
}

/// Learning opportunity for developers
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LearningOpportunity {
    /// Topic to learn about
    pub topic: String,
    
    /// Relevance to current error
    pub relevance: f64,
    
    /// Suggested resources
    pub resources: Vec<LearningResource>,
    
    /// Practical exercises
    pub exercises: Vec<Exercise>,
}

/// Automation suggestion for tools
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct AutomationSuggestion {
    /// Type of automation
    pub automation_type: AutomationType,
    
    /// Confidence in automation success
    pub confidence: f64,
    
    /// Required tool capabilities
    pub required_capabilities: Vec<ToolCapability>,
    
    /// Automation steps
    pub steps: Vec<AutomationStep>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum AutomationType {
    /// Automatic code fix
    AutoFix,
    
    /// Code generation
    CodeGeneration,
    
    /// Refactoring suggestion
    Refactoring,
    
    /// Documentation generation
    DocumentationGeneration,
    
    /// Test generation
    TestGeneration,
}
```

### 2. Educational Content Generation

**Inspired by**: Elm's educational error messages and Rust's error explanations

```rust
/// Educational content generator for diagnostics
pub struct EducationalContentGenerator {
    /// Content database
    content_db: Arc<ContentDatabase>,
    
    /// AI content generator
    ai_generator: Option<Arc<AIContentGenerator>>,
    
    /// Learning path analyzer
    learning_analyzer: Arc<LearningPathAnalyzer>,
}

impl EducationalContentGenerator {
    /// Generate educational content for a diagnostic
    pub fn generate_content(
        &self,
        diagnostic: &PrismDiagnostic,
        user_context: &UserContext,
    ) -> Result<EducationalContent, ContentGenerationError> {
        let mut content = EducationalContent::new();
        
        // Core concept explanation
        content.core_concept = self.generate_core_concept_explanation(diagnostic)?;
        
        // Why this error occurs
        content.error_explanation = self.generate_error_explanation(diagnostic)?;
        
        // How to fix it
        content.fix_explanation = self.generate_fix_explanation(diagnostic)?;
        
        // Related concepts
        content.related_concepts = self.find_related_concepts(diagnostic)?;
        
        // Examples
        content.examples = self.generate_examples(diagnostic, user_context)?;
        
        // Further reading
        content.further_reading = self.suggest_further_reading(diagnostic, user_context)?;
        
        Ok(content)
    }
    
    /// Generate core concept explanation
    fn generate_core_concept_explanation(
        &self,
        diagnostic: &PrismDiagnostic,
    ) -> Result<ConceptExplanation, ContentGenerationError> {
        match &diagnostic.base.severity {
            Severity::Error => {
                match diagnostic.ai_metadata.error_category {
                    ErrorCategory::Type { semantic_level, .. } => {
                        self.explain_type_system_concept(semantic_level)
                    }
                    ErrorCategory::Effect { capability_type, .. } => {
                        self.explain_effect_system_concept(capability_type)
                    }
                    ErrorCategory::Architecture { cohesion_impact, .. } => {
                        self.explain_architecture_concept(cohesion_impact)
                    }
                    _ => self.generate_generic_explanation(diagnostic),
                }
            }
            _ => self.generate_generic_explanation(diagnostic),
        }
    }
    
    /// Generate practical examples
    fn generate_examples(
        &self,
        diagnostic: &PrismDiagnostic,
        user_context: &UserContext,
    ) -> Result<Vec<CodeExample>, ContentGenerationError> {
        let mut examples = Vec::new();
        
        // Bad example (what caused the error)
        if let Some(bad_example) = self.create_bad_example(diagnostic)? {
            examples.push(bad_example);
        }
        
        // Good example (correct way to do it)
        if let Some(good_example) = self.create_good_example(diagnostic)? {
            examples.push(good_example);
        }
        
        // Alternative approaches
        let alternatives = self.create_alternative_examples(diagnostic, user_context)?;
        examples.extend(alternatives);
        
        Ok(examples)
    }
}

/// Educational content for a diagnostic
#[derive(Debug, Clone)]
pub struct EducationalContent {
    /// Core concept explanation
    pub core_concept: ConceptExplanation,
    
    /// Why this error occurs
    pub error_explanation: ErrorExplanation,
    
    /// How to fix it
    pub fix_explanation: FixExplanation,
    
    /// Related concepts to learn
    pub related_concepts: Vec<RelatedConcept>,
    
    /// Code examples
    pub examples: Vec<CodeExample>,
    
    /// Further reading suggestions
    pub further_reading: Vec<ReadingResource>,
}

/// Code example with explanation
#[derive(Debug, Clone)]
pub struct CodeExample {
    /// Example title
    pub title: String,
    
    /// Example code
    pub code: String,
    
    /// Explanation of the example
    pub explanation: String,
    
    /// Whether this is a good or bad example
    pub example_type: ExampleType,
    
    /// Key learning points
    pub key_points: Vec<String>,
}

#[derive(Debug, Clone, PartialEq, Eq)]
pub enum ExampleType {
    /// Shows the incorrect approach
    BadExample,
    
    /// Shows the correct approach
    GoodExample,
    
    /// Shows an alternative approach
    Alternative,
    
    /// Shows a more advanced approach
    Advanced,
}
```

## Multi-Phase Error Integration

### 1. Cross-Phase Error Correlation

**Inspired by**: Rust's trait solver and TypeScript's flow analysis

```rust
/// System for correlating errors across compiler phases
pub struct CrossPhaseErrorCorrelator {
    /// Error graph for tracking relationships
    error_graph: ErrorRelationshipGraph,
    
    /// Phase-specific analyzers
    phase_analyzers: HashMap<CompilerPhase, Box<dyn PhaseErrorAnalyzer>>,
    
    /// Root cause analyzer
    root_cause_analyzer: RootCauseAnalyzer,
}

impl CrossPhaseErrorCorrelator {
    /// Correlate errors from multiple compiler phases
    pub fn correlate_errors(
        &mut self,
        phase_errors: HashMap<CompilerPhase, Vec<CompilerError>>,
    ) -> Result<Vec<CorrelatedErrorGroup>, CorrelationError> {
        // Build error relationship graph
        for (phase, errors) in &phase_errors {
            for error in errors {
                self.error_graph.add_error(*phase, error.clone());
            }
        }
        
        // Find relationships between errors
        self.find_error_relationships(&phase_errors)?;
        
        // Group related errors
        let error_groups = self.group_related_errors()?;
        
        // Analyze root causes
        let correlated_groups = self.analyze_root_causes(error_groups)?;
        
        Ok(correlated_groups)
    }
    
    /// Find relationships between errors from different phases
    fn find_error_relationships(
        &mut self,
        phase_errors: &HashMap<CompilerPhase, Vec<CompilerError>>,
    ) -> Result<(), CorrelationError> {
        // Look for cascading errors
        self.find_cascading_errors(phase_errors)?;
        
        // Look for common root causes
        self.find_common_root_causes(phase_errors)?;
        
        // Look for semantic relationships
        self.find_semantic_relationships(phase_errors)?;
        
        Ok(())
    }
    
    /// Find cascading errors (where one error causes others)
    fn find_cascading_errors(
        &mut self,
        phase_errors: &HashMap<CompilerPhase, Vec<CompilerError>>,
    ) -> Result<(), CorrelationError> {
        // Parse errors can cause type errors
        if let (Some(parse_errors), Some(type_errors)) = (
            phase_errors.get(&CompilerPhase::Parse),
            phase_errors.get(&CompilerPhase::TypeCheck),
        ) {
            for parse_error in parse_errors {
                for type_error in type_errors {
                    if self.is_cascading_error(parse_error, type_error)? {
                        self.error_graph.add_relationship(
                            parse_error.id(),
                            type_error.id(),
                            ErrorRelationship::Cascading,
                        );
                    }
                }
            }
        }
        
        // Type errors can cause effect errors
        if let (Some(type_errors), Some(effect_errors)) = (
            phase_errors.get(&CompilerPhase::TypeCheck),
            phase_errors.get(&CompilerPhase::EffectCheck),
        ) {
            for type_error in type_errors {
                for effect_error in effect_errors {
                    if self.is_cascading_error(type_error, effect_error)? {
                        self.error_graph.add_relationship(
                            type_error.id(),
                            effect_error.id(),
                            ErrorRelationship::Cascading,
                        );
                    }
                }
            }
        }
        
        Ok(())
    }
}

/// Group of correlated errors with analysis
#[derive(Debug, Clone)]
pub struct CorrelatedErrorGroup {
    /// Primary error (root cause)
    pub primary_error: CompilerError,
    
    /// Secondary errors (consequences)
    pub secondary_errors: Vec<CompilerError>,
    
    /// Root cause analysis
    pub root_cause_analysis: RootCauseAnalysis,
    
    /// Combined diagnostic
    pub combined_diagnostic: PrismDiagnostic,
    
    /// Group-level suggestions
    pub group_suggestions: Vec<GroupLevelSuggestion>,
}

/// Root cause analysis for error groups
#[derive(Debug, Clone)]
pub struct RootCauseAnalysis {
    /// Identified root cause
    pub root_cause: RootCause,
    
    /// Confidence in the analysis
    pub confidence: f64,
    
    /// Contributing factors
    pub contributing_factors: Vec<ContributingFactor>,
    
    /// Impact analysis
    pub impact_analysis: ImpactAnalysis,
}

#[derive(Debug, Clone)]
pub enum RootCause {
    /// Syntax error that cascaded
    SyntaxError {
        original_error: CompilerError,
        cascade_pattern: CascadePattern,
    },
    
    /// Type system misunderstanding
    TypeSystemMisunderstanding {
        concept: String,
        misconception: String,
        correct_understanding: String,
    },
    
    /// Architectural violation
    ArchitecturalViolation {
        violated_principle: String,
        suggested_pattern: String,
    },
    
    /// Business rule violation
    BusinessRuleViolation {
        rule: BusinessRule,
        violation_context: String,
    },
    
    /// Missing knowledge
    MissingKnowledge {
        knowledge_gap: String,
        learning_resources: Vec<LearningResource>,
    },
}
```

### 2. Progressive Error Disclosure

**Inspired by**: Progressive disclosure in UI design, applied to error reporting

```rust
/// Progressive error disclosure system
pub struct ProgressiveErrorDisclosure {
    /// User experience level
    user_level: UserExperienceLevel,
    
    /// Error complexity analyzer
    complexity_analyzer: ErrorComplexityAnalyzer,
    
    /// Disclosure strategy selector
    strategy_selector: DisclosureStrategySelector,
}

impl ProgressiveErrorDisclosure {
    /// Generate progressive error disclosure
    pub fn generate_disclosure(
        &self,
        diagnostic: &PrismDiagnostic,
        user_context: &UserContext,
    ) -> Result<ProgressiveDisclosure, DisclosureError> {
        let complexity = self.complexity_analyzer.analyze_complexity(diagnostic)?;
        let strategy = self.strategy_selector.select_strategy(complexity, user_context)?;
        
        match strategy {
            DisclosureStrategy::Simple => self.generate_simple_disclosure(diagnostic),
            DisclosureStrategy::Detailed => self.generate_detailed_disclosure(diagnostic),
            DisclosureStrategy::Expert => self.generate_expert_disclosure(diagnostic),
            DisclosureStrategy::Educational => self.generate_educational_disclosure(diagnostic),
        }
    }
    
    /// Generate simple disclosure for beginners
    fn generate_simple_disclosure(
        &self,
        diagnostic: &PrismDiagnostic,
    ) -> Result<ProgressiveDisclosure, DisclosureError> {
        Ok(ProgressiveDisclosure {
            level: DisclosureLevel::Simple,
            primary_message: self.simplify_error_message(&diagnostic.base.message)?,
            quick_fix: diagnostic.suggested_fixes.first().cloned(),
            explanation: self.generate_simple_explanation(diagnostic)?,
            next_steps: self.generate_simple_next_steps(diagnostic)?,
            expansion_available: true,
        })
    }
    
    /// Generate detailed disclosure for intermediate users
    fn generate_detailed_disclosure(
        &self,
        diagnostic: &PrismDiagnostic,
    ) -> Result<ProgressiveDisclosure, DisclosureError> {
        Ok(ProgressiveDisclosure {
            level: DisclosureLevel::Detailed,
            primary_message: diagnostic.base.message.clone(),
            quick_fix: diagnostic.suggested_fixes.first().cloned(),
            explanation: self.generate_detailed_explanation(diagnostic)?,
            next_steps: self.generate_detailed_next_steps(diagnostic)?,
            semantic_context: diagnostic.semantic_context.clone(),
            business_context: diagnostic.business_context.clone(),
            expansion_available: true,
        })
    }
    
    /// Generate expert disclosure for advanced users
    fn generate_expert_disclosure(
        &self,
        diagnostic: &PrismDiagnostic,
    ) -> Result<ProgressiveDisclosure, DisclosureError> {
        Ok(ProgressiveDisclosure {
            level: DisclosureLevel::Expert,
            primary_message: diagnostic.base.message.clone(),
            all_fixes: diagnostic.suggested_fixes.clone(),
            full_context: Some(FullContext {
                semantic_context: diagnostic.semantic_context.clone(),
                business_context: diagnostic.business_context.clone(),
                effect_context: diagnostic.effect_context.clone(),
                cohesion_context: diagnostic.cohesion_context.clone(),
            }),
            ai_metadata: Some(diagnostic.ai_metadata.clone()),
            related_diagnostics: diagnostic.related_diagnostics.clone(),
            expansion_available: false,
        })
    }
}

/// Progressive disclosure levels
#[derive(Debug, Clone)]
pub enum DisclosureLevel {
    /// Simple message with basic fix
    Simple,
    
    /// Detailed explanation with context
    Detailed,
    
    /// Full technical details
    Expert,
    
    /// Educational content included
    Educational,
}

/// Progressive disclosure structure
#[derive(Debug, Clone)]
pub struct ProgressiveDisclosure {
    /// Disclosure level
    pub level: DisclosureLevel,
    
    /// Primary error message
    pub primary_message: String,
    
    /// Quick fix suggestion (if available)
    pub quick_fix: Option<SuggestedFix>,
    
    /// All available fixes (expert level)
    pub all_fixes: Option<Vec<SuggestedFix>>,
    
    /// Explanation appropriate to level
    pub explanation: Option<String>,
    
    /// Next steps for user
    pub next_steps: Option<Vec<String>>,
    
    /// Semantic context (detailed level)
    pub semantic_context: Option<SemanticContext>,
    
    /// Business context (detailed level)
    pub business_context: Option<BusinessContext>,
    
    /// Full context information (expert level)
    pub full_context: Option<FullContext>,
    
    /// AI metadata (expert level)
    pub ai_metadata: Option<DiagnosticAIMetadata>,
    
    /// Related diagnostics (expert level)
    pub related_diagnostics: Option<Vec<RelatedDiagnostic>>,
    
    /// Whether more details are available
    pub expansion_available: bool,
}
```

## Implementation Details

### 1. Diagnostic Collection and Aggregation

```rust
/// Central diagnostic collector that aggregates errors from all compiler phases
pub struct DiagnosticCollector {
    /// Collected diagnostics by phase
    phase_diagnostics: HashMap<CompilerPhase, Vec<PrismDiagnostic>>,
    
    /// Error correlator
    correlator: CrossPhaseErrorCorrelator,
    
    /// Progressive disclosure generator
    disclosure_generator: ProgressiveErrorDisclosure,
    
    /// AI metadata exporter
    ai_exporter: DiagnosticAIExporter,
    
    /// Configuration
    config: DiagnosticConfig,
}

impl DiagnosticCollector {
    /// Add diagnostic from a specific compiler phase
    pub fn add_diagnostic(
        &mut self,
        phase: CompilerPhase,
        diagnostic: PrismDiagnostic,
    ) {
        self.phase_diagnostics
            .entry(phase)
            .or_insert_with(Vec::new)
            .push(diagnostic);
    }
    
    /// Finalize diagnostics and generate comprehensive report
    pub fn finalize(
        &mut self,
        user_context: &UserContext,
    ) -> Result<DiagnosticReport, DiagnosticError> {
        // Correlate errors across phases
        let phase_errors: HashMap<CompilerPhase, Vec<CompilerError>> = self
            .phase_diagnostics
            .iter()
            .map(|(phase, diagnostics)| {
                let errors = diagnostics
                    .iter()
                    .map(|d| CompilerError::from_diagnostic(d))
                    .collect();
                (*phase, errors)
            })
            .collect();
        
        let correlated_groups = self.correlator.correlate_errors(phase_errors)?;
        
        // Generate progressive disclosures
        let mut disclosures = Vec::new();
        for group in &correlated_groups {
            let disclosure = self.disclosure_generator.generate_disclosure(
                &group.combined_diagnostic,
                user_context,
            )?;
            disclosures.push(disclosure);
        }
        
        // Generate AI metadata export
        let ai_export = self.ai_exporter.export_diagnostics(&correlated_groups)?;
        
        Ok(DiagnosticReport {
            correlated_groups,
            progressive_disclosures: disclosures,
            ai_export,
            summary: self.generate_summary(&correlated_groups)?,
            recommendations: self.generate_recommendations(&correlated_groups)?,
        })
    }
    
    /// Generate summary of all diagnostics
    fn generate_summary(
        &self,
        groups: &[CorrelatedErrorGroup],
    ) -> Result<DiagnosticSummary, DiagnosticError> {
        let mut summary = DiagnosticSummary::new();
        
        for group in groups {
            match group.primary_error.severity() {
                Severity::Error => summary.error_count += 1,
                Severity::Warning => summary.warning_count += 1,
                Severity::Info => summary.info_count += 1,
                Severity::Hint => summary.hint_count += 1,
            }
            
            // Categorize errors
            summary.category_breakdown.entry(group.primary_error.category())
                .and_modify(|count| *count += 1)
                .or_insert(1);
        }
        
        // Generate insights
        summary.insights = self.generate_insights(groups)?;
        
        Ok(summary)
    }
}

/// Comprehensive diagnostic report
#[derive(Debug, Clone)]
pub struct DiagnosticReport {
    /// Correlated error groups
    pub correlated_groups: Vec<CorrelatedErrorGroup>,
    
    /// Progressive disclosures for each group
    pub progressive_disclosures: Vec<ProgressiveDisclosure>,
    
    /// AI-readable export
    pub ai_export: DiagnosticAIExport,
    
    /// Summary of all diagnostics
    pub summary: DiagnosticSummary,
    
    /// High-level recommendations
    pub recommendations: Vec<Recommendation>,
}

/// Summary of diagnostic analysis
#[derive(Debug, Clone)]
pub struct DiagnosticSummary {
    /// Count by severity
    pub error_count: usize,
    pub warning_count: usize,
    pub info_count: usize,
    pub hint_count: usize,
    
    /// Breakdown by category
    pub category_breakdown: HashMap<ErrorCategory, usize>,
    
    /// Key insights
    pub insights: Vec<DiagnosticInsight>,
    
    /// Overall code health score
    pub health_score: f64,
}

/// High-level recommendation for improving code
#[derive(Debug, Clone)]
pub struct Recommendation {
    /// Recommendation title
    pub title: String,
    
    /// Detailed description
    pub description: String,
    
    /// Priority level
    pub priority: RecommendationPriority,
    
    /// Estimated effort
    pub effort: EstimatedEffort,
    
    /// Expected benefit
    pub benefit: ExpectedBenefit,
    
    /// Specific actions to take
    pub actions: Vec<RecommendationAction>,
}

#[derive(Debug, Clone, PartialEq, Eq, PartialOrd, Ord)]
pub enum RecommendationPriority {
    Critical,
    High,
    Medium,
    Low,
}
```

### 2. IDE and Language Server Integration

**Inspired by**: Language Server Protocol and modern IDE diagnostics

```rust
/// Language server integration for diagnostics
pub struct DiagnosticLanguageServer {
    /// Diagnostic collector
    collector: Arc<Mutex<DiagnosticCollector>>,
    
    /// LSP client for sending diagnostics
    client: Arc<dyn LanguageServerClient>,
    
    /// Diagnostic cache
    diagnostic_cache: Arc<Mutex<DiagnosticCache>>,
    
    /// Configuration
    config: DiagnosticLSPConfig,
}

impl DiagnosticLanguageServer {
    /// Publish diagnostics to LSP client
    pub async fn publish_diagnostics(
        &self,
        uri: Url,
        diagnostics: Vec<PrismDiagnostic>,
    ) -> Result<(), LSPError> {
        let lsp_diagnostics: Vec<lsp_types::Diagnostic> = diagnostics
            .into_iter()
            .map(|d| self.convert_to_lsp_diagnostic(d))
            .collect::<Result<Vec<_>, _>>()?;
        
        self.client
            .publish_diagnostics(PublishDiagnosticsParams {
                uri,
                diagnostics: lsp_diagnostics,
                version: None,
            })
            .await?;
        
        Ok(())
    }
    
    /// Convert Prism diagnostic to LSP diagnostic
    fn convert_to_lsp_diagnostic(
        &self,
        diagnostic: PrismDiagnostic,
    ) -> Result<lsp_types::Diagnostic, ConversionError> {
        let mut lsp_diagnostic = lsp_types::Diagnostic {
            range: self.span_to_range(diagnostic.base.span)?,
            severity: Some(self.severity_to_lsp(diagnostic.base.severity)),
            code: Some(lsp_types::NumberOrString::String(
                diagnostic.ai_metadata.error_pattern.code.clone()
            )),
            code_description: None,
            source: Some("prism".to_string()),
            message: diagnostic.base.message.clone(),
            related_information: None,
            tags: None,
            data: None,
        };
        
        // Add related information
        if !diagnostic.related_diagnostics.is_empty() {
            let related_info: Vec<DiagnosticRelatedInformation> = diagnostic
                .related_diagnostics
                .into_iter()
                .map(|rd| DiagnosticRelatedInformation {
                    location: lsp_types::Location {
                        uri: rd.uri,
                        range: self.span_to_range(rd.span)?,
                    },
                    message: rd.message,
                })
                .collect::<Result<Vec<_>, _>>()?;
            
            lsp_diagnostic.related_information = Some(related_info);
        }
        
        Ok(lsp_diagnostic)
    }
    
    /// Provide code actions for diagnostics
    pub async fn code_action(
        &self,
        params: CodeActionParams,
    ) -> Result<Option<CodeActionResponse>, LSPError> {
        let mut actions = Vec::new();
        
        // Get cached diagnostics for this range
        let cached_diagnostics = self.diagnostic_cache
            .lock()
            .unwrap()
            .get_diagnostics_in_range(&params.text_document.uri, &params.range);
        
        for diagnostic in cached_diagnostics {
            // Convert suggested fixes to code actions
            for fix in diagnostic.suggested_fixes {
                let code_action = self.suggested_fix_to_code_action(fix, &params.text_document.uri)?;
                actions.push(CodeActionOrCommand::CodeAction(code_action));
            }
        }
        
        Ok(Some(actions))
    }
    
    /// Convert suggested fix to LSP code action
    fn suggested_fix_to_code_action(
        &self,
        fix: SuggestedFix,
        uri: &Url,
    ) -> Result<CodeAction, ConversionError> {
        let mut text_edits = Vec::new();
        
        for change in fix.code_changes {
            text_edits.push(TextEdit {
                range: self.span_to_range(change.span)?,
                new_text: change.new_text,
            });
        }
        
        let workspace_edit = WorkspaceEdit {
            changes: Some(HashMap::from([(uri.clone(), text_edits)])),
            document_changes: None,
            change_annotations: None,
        };
        
        Ok(CodeAction {
            title: fix.description,
            kind: Some(self.fix_type_to_code_action_kind(fix.fix_type)),
            diagnostics: None,
            edit: Some(workspace_edit),
            command: None,
            is_preferred: Some(fix.confidence > 0.8),
            disabled: None,
            data: None,
        })
    }
}
```

## Performance Considerations

### 1. Lazy Error Analysis

```rust
/// Lazy error analysis for performance optimization
pub struct LazyErrorAnalyzer {
    /// Analysis cache
    analysis_cache: Arc<Mutex<AnalysisCache>>,
    
    /// Background analysis executor
    background_executor: Arc<BackgroundAnalysisExecutor>,
    
    /// Analysis priority queue
    priority_queue: Arc<Mutex<AnalysisPriorityQueue>>,
}

impl LazyErrorAnalyzer {
    /// Analyze error with lazy evaluation
    pub fn analyze_lazy(
        &self,
        error: &CompilerError,
        context: &SourceContext,
        priority: AnalysisPriority,
    ) -> Result<LazyAnalysisResult, AnalysisError> {
        // Check cache first
        if let Some(cached) = self.analysis_cache.lock().unwrap().get(error) {
            return Ok(LazyAnalysisResult::Cached(cached));
        }
        
        match priority {
            AnalysisPriority::Immediate => {
                // Perform analysis immediately
                let analysis = self.perform_full_analysis(error, context)?;
                self.analysis_cache.lock().unwrap().insert(error.clone(), analysis.clone());
                Ok(LazyAnalysisResult::Immediate(analysis))
            }
            AnalysisPriority::Background => {
                // Schedule for background analysis
                self.priority_queue.lock().unwrap().enqueue(
                    error.clone(),
                    context.clone(),
                    priority,
                );
                Ok(LazyAnalysisResult::Scheduled)
            }
            AnalysisPriority::OnDemand => {
                // Return placeholder, analyze when requested
                Ok(LazyAnalysisResult::OnDemand(Box::new(move || {
                    self.perform_full_analysis(error, context)
                })))
            }
        }
    }
}

/// Memory-efficient diagnostic storage
pub struct CompactDiagnosticStorage {
    /// String interner for messages
    string_interner: Arc<Mutex<StringInterner>>,
    
    /// Compressed diagnostic data
    compressed_diagnostics: Vec<CompressedDiagnostic>,
    
    /// Span compression
    span_compressor: SpanCompressor,
}

impl CompactDiagnosticStorage {
    /// Store diagnostic in compressed format
    pub fn store_diagnostic(&mut self, diagnostic: PrismDiagnostic) -> DiagnosticId {
        let compressed = CompressedDiagnostic {
            message_id: self.string_interner.lock().unwrap().intern(&diagnostic.base.message),
            severity: diagnostic.base.severity,
            compressed_span: self.span_compressor.compress(diagnostic.base.span),
            category_bits: self.compress_category(&diagnostic.ai_metadata.error_category),
            has_semantic_context: diagnostic.semantic_context.is_some(),
            has_business_context: diagnostic.business_context.is_some(),
            has_effect_context: diagnostic.effect_context.is_some(),
            fix_count: diagnostic.suggested_fixes.len() as u8,
        };
        
        let id = DiagnosticId(self.compressed_diagnostics.len());
        self.compressed_diagnostics.push(compressed);
        id
    }
}
```

### 2. Incremental Diagnostic Updates

```rust
/// Incremental diagnostic update system
pub struct IncrementalDiagnosticUpdater {
    /// Previous diagnostic state
    previous_state: Arc<Mutex<DiagnosticState>>,
    
    /// Change tracker
    change_tracker: Arc<ChangeTracker>,
    
    /// Dependency graph
    dependency_graph: Arc<DiagnosticDependencyGraph>,
}

impl IncrementalDiagnosticUpdater {
    /// Update diagnostics incrementally based on changes
    pub fn update_incrementally(
        &self,
        changes: &[SourceChange],
        current_state: &DiagnosticState,
    ) -> Result<DiagnosticUpdate, UpdateError> {
        let mut update = DiagnosticUpdate::new();
        
        // Determine which diagnostics are affected by changes
        let affected_diagnostics = self.find_affected_diagnostics(changes)?;
        
        // Remove outdated diagnostics
        for diagnostic_id in &affected_diagnostics {
            update.removed_diagnostics.push(*diagnostic_id);
        }
        
        // Recompute affected diagnostics
        for diagnostic_id in &affected_diagnostics {
            if let Some(new_diagnostic) = self.recompute_diagnostic(*diagnostic_id, current_state)? {
                update.added_diagnostics.push(new_diagnostic);
            }
        }
        
        // Update dependency graph
        self.dependency_graph.update(&update)?;
        
        Ok(update)
    }
}
```

## Testing Strategy

### 1. Diagnostic Quality Testing

```rust
#[cfg(test)]
mod diagnostic_quality_tests {
    use super::*;
    
    /// Test that diagnostics provide actionable information
    #[test]
    fn test_diagnostic_actionability() {
        let test_cases = vec![
            TestCase {
                code: "let x: String = 42",
                expected_category: ErrorCategory::Type { .. },
                expected_fixes: vec![
                    "Convert 42 to String",
                    "Change type annotation to i32",
                ],
            },
            TestCase {
                code: "function processPayment() effects [Network.Send] { /* no capability */ }",
                expected_category: ErrorCategory::Effect { .. },
                expected_fixes: vec![
                    "Add Network capability",
                    "Remove Network.Send effect",
                ],
            },
        ];
        
        for test_case in test_cases {
            let diagnostic = analyze_code(&test_case.code).unwrap();
            
            // Should have actionable suggestions
            assert!(!diagnostic.suggested_fixes.is_empty());
            
            // Suggestions should be relevant
            for fix in &diagnostic.suggested_fixes {
                assert!(test_case.expected_fixes.iter().any(|expected| 
                    fix.description.contains(expected)
                ));
            }
        }
    }
    
    /// Test AI metadata completeness
    #[test]
    fn test_ai_metadata_completeness() {
        let diagnostic = create_test_diagnostic();
        let ai_export = DiagnosticAIExporter::new().export_diagnostic(&diagnostic).unwrap();
        
        // Should have complete semantic analysis
        assert!(ai_export.semantic_analysis.type_information.len() > 0);
        assert!(ai_export.semantic_analysis.semantic_relationships.len() > 0);
        
        // Should have learning opportunities
        assert!(ai_export.learning_opportunities.len() > 0);
        
        // Should have automation suggestions
        assert!(ai_export.automation_suggestions.len() > 0);
    }
    
    /// Test progressive disclosure appropriateness
    #[test]
    fn test_progressive_disclosure() {
        let diagnostic = create_complex_diagnostic();
        let disclosure_generator = ProgressiveErrorDisclosure::new();
        
        // Beginner context should get simple disclosure
        let beginner_context = UserContext { experience_level: UserExperienceLevel::Beginner, .. };
        let beginner_disclosure = disclosure_generator
            .generate_disclosure(&diagnostic, &beginner_context)
            .unwrap();
        
        assert_eq!(beginner_disclosure.level, DisclosureLevel::Simple);
        assert!(beginner_disclosure.explanation.is_some());
        assert!(beginner_disclosure.quick_fix.is_some());
        
        // Expert context should get full disclosure
        let expert_context = UserContext { experience_level: UserExperienceLevel::Expert, .. };
        let expert_disclosure = disclosure_generator
            .generate_disclosure(&diagnostic, &expert_context)
            .unwrap();
        
        assert_eq!(expert_disclosure.level, DisclosureLevel::Expert);
        assert!(expert_disclosure.full_context.is_some());
        assert!(expert_disclosure.ai_metadata.is_some());
    }
}

/// Property-based testing for diagnostic consistency
#[cfg(test)]
mod property_tests {
    use super::*;
    use proptest::prelude::*;
    
    proptest! {
        /// Every diagnostic should have at least one suggested fix
        #[test]
        fn every_error_has_suggested_fix(
            code in arbitrary_prism_code_with_errors()
        ) {
            let diagnostics = analyze_code(&code).unwrap();
            
            for diagnostic in diagnostics {
                if diagnostic.base.severity == Severity::Error {
                    prop_assert!(
                        !diagnostic.suggested_fixes.is_empty(),
                        "Error diagnostic should have at least one suggested fix"
                    );
                }
            }
        }
        
        /// AI metadata should be consistent across similar errors
        #[test]
        fn ai_metadata_consistency(
            error_type in arbitrary_error_type(),
            variations in prop::collection::vec(arbitrary_error_variation(), 2..5)
        ) {
            let diagnostics: Vec<PrismDiagnostic> = variations
                .into_iter()
                .map(|var| create_diagnostic_with_variation(error_type, var))
                .collect();
            
            // All diagnostics of the same type should have similar AI metadata structure
            let first_metadata = &diagnostics[0].ai_metadata;
            
            for diagnostic in &diagnostics[1..] {
                prop_assert_eq!(
                    diagnostic.ai_metadata.error_category,
                    first_metadata.error_category,
                    "Similar errors should have the same category"
                );
                
                prop_assert!(
                    (diagnostic.ai_metadata.confidence - first_metadata.confidence).abs() < 0.3,
                    "Similar errors should have similar confidence levels"
                );
            }
        }
    }
}
```

### 2. Performance Testing

```rust
#[cfg(test)]
mod performance_tests {
    use super::*;
    use std::time::Instant;
    
    /// Test diagnostic generation performance
    #[test]
    fn test_diagnostic_performance() {
        let large_codebase = generate_large_codebase(1000); // 1000 files
        
        let start = Instant::now();
        let diagnostics = analyze_codebase(&large_codebase).unwrap();
        let duration = start.elapsed();
        
        // Should analyze large codebase in reasonable time
        assert!(duration.as_secs() < 10, "Analysis took too long: {:?}", duration);
        
        // Should generate comprehensive diagnostics
        assert!(diagnostics.len() > 0);
        
        // AI metadata should be generated for all errors
        let errors: Vec<_> = diagnostics
            .iter()
            .filter(|d| d.base.severity == Severity::Error)
            .collect();
        
        for error in errors {
            assert!(error.ai_metadata.confidence > 0.0);
            assert!(!error.ai_metadata.involved_elements.is_empty());
        }
    }
    
    /// Test incremental update performance
    #[test]
    fn test_incremental_performance() {
        let mut diagnostic_system = DiagnosticSystem::new();
        let initial_code = generate_large_codebase(100);
        
        // Initial analysis
        let start = Instant::now();
        diagnostic_system.analyze_full(&initial_code).unwrap();
        let initial_duration = start.elapsed();
        
        // Small change
        let modified_code = make_small_change(&initial_code);
        
        let start = Instant::now();
        diagnostic_system.analyze_incremental(&modified_code).unwrap();
        let incremental_duration = start.elapsed();
        
        // Incremental should be much faster
        assert!(
            incremental_duration < initial_duration / 10,
            "Incremental analysis should be much faster than full analysis"
        );
    }
}
```

## Integration Points

### 1. Query Engine Integration (PLT-006)

```rust
/// Query-based diagnostic computation
pub struct DiagnosticQuery;

impl Query for DiagnosticQuery {
    type Input = DiagnosticRequest;
    type Output = PrismDiagnostic;
    
    fn execute(
        &self,
        input: Self::Input,
        context: &QueryContext,
    ) -> Result<Self::Output, QueryError> {
        let analyzer = context.get_contextual_error_analyzer();
        analyzer.analyze_error(&input.error, &input.source_context)
            .map_err(QueryError::from)
    }
    
    fn cache_key(&self, input: &Self::Input) -> CacheKey {
        let mut hasher = DefaultHasher::new();
        input.error.hash(&mut hasher);
        input.source_context.hash(&mut hasher);
        CacheKey::from_hash(hasher.finish())
    }
    
    fn dependencies(&self, input: &Self::Input) -> Vec<QueryDependency> {
        vec![
            QueryDependency::SourceFile {
                file_id: input.source_context.file_id,
            },
            QueryDependency::SemanticAnalysis {
                span: input.error.span(),
            },
            QueryDependency::TypeInformation {
                span: input.error.span(),
            },
        ]
    }
}
```

### 2. AI Metadata Export Integration

```rust
/// AI metadata export for diagnostics
impl DiagnosticAIExporter {
    /// Export diagnostic for AI consumption
    pub fn export_for_ai(
        &self,
        diagnostic: &PrismDiagnostic,
    ) -> Result<AIExportFormat, ExportError> {
        Ok(AIExportFormat {
            diagnostic_metadata: self.extract_diagnostic_metadata(diagnostic)?,
            code_context: self.extract_code_context(diagnostic)?,
            semantic_analysis: self.extract_semantic_analysis(diagnostic)?,
            learning_context: self.extract_learning_context(diagnostic)?,
            automation_hints: self.extract_automation_hints(diagnostic)?,
        })
    }
}
```

## Open Issues

### Issue 1: AI-Generated Suggestion Quality

**Problem**: Ensuring AI-generated diagnostic suggestions are consistently helpful and accurate.

**Research Direction**: Develop validation frameworks for AI suggestions, implement feedback loops, and create quality metrics for suggestion effectiveness.

### Issue 2: Cross-Language Error Correlation

**Problem**: Correlating errors across different syntax styles in multi-syntax codebases.

**Research Direction**: Design semantic equivalence detection and develop unified error pattern recognition across syntax styles.

### Issue 3: Performance at Scale

**Problem**: Maintaining real-time diagnostic performance in very large codebases.

**Research Direction**: Investigate distributed diagnostic computation, advanced caching strategies, and selective analysis techniques.

### Issue 4: Educational Content Generation

**Problem**: Automatically generating high-quality educational content for complex errors.

**Research Direction**: Develop content generation models, create content quality metrics, and implement user feedback integration.

## References

1. **[Rust Error Handling](https://doc.rust-lang.org/book/ch09-00-error-handling.html)** - Excellent error messages and suggestions
2. **[TypeScript Diagnostics](https://github.com/microsoft/TypeScript/wiki/Coding-guidelines#diagnostic-messages)** - Contextual error reporting
3. **[Elm Error Messages](https://elm-lang.org/news/compiler-errors-for-humans)** - Human-friendly compiler errors
4. **[Language Server Protocol](https://microsoft.github.io/language-server-protocol/)** - Diagnostic reporting standards
5. **[Clang Diagnostics](https://clang.llvm.org/docs/DiagnosticsReference.html)** - Comprehensive diagnostic system
6. **[Swift Error Handling](https://docs.swift.org/swift-book/LanguageGuide/ErrorHandling.html)** - Contextual error recovery
7. **[PLT-003]** Parsing Strategies & Error Recovery - Foundation for error recovery
8. **[PLT-005]** Type Checking Implementation - Type error diagnostics
9. **[PLD-001]** Semantic Type System - Semantic error context
10. **[PLD-003]** Effect System & Capabilities - Effect error handling

## Appendices

### Appendix A: Error Message Templates

```rust
/// Templates for generating consistent error messages
pub struct ErrorMessageTemplates {
    templates: HashMap<ErrorCategory, MessageTemplate>,
}

impl ErrorMessageTemplates {
    /// Generate message from template
    pub fn generate_message(
        &self,
        category: &ErrorCategory,
        context: &ErrorContext,
    ) -> String {
        match category {
            ErrorCategory::Type { .. } => {
                format!(
                    "Type mismatch: expected '{}', found '{}'\n\
                     In {}: {}\n\
                     {} suggests: {}",
                    context.expected_type,
                    context.actual_type,
                    context.business_context.unwrap_or("this context"),
                    context.semantic_meaning.unwrap_or("type compatibility required"),
                    context.ai_assistant_name,
                    context.ai_suggestion.unwrap_or("check type annotations")
                )
            }
            ErrorCategory::Effect { .. } => {
                format!(
                    "Missing capability '{}' for effect '{}'\n\
                     This operation requires: {}\n\
                     Available capabilities: {}\n\
                     Suggestion: {}",
                    context.missing_capability.unwrap(),
                    context.effect.unwrap(),
                    context.required_capabilities.join(", "),
                    context.available_capabilities.join(", "),
                    context.capability_suggestion.unwrap_or("add required capability")
                )
            }
            _ => self.generate_generic_message(category, context),
        }
    }
}
```

### Appendix B: Diagnostic Configuration Schema

```toml
[diagnostics]
# Enable AI-enhanced diagnostics
enable_ai_enhancement = true

# Diagnostic verbosity level
verbosity = "detailed"  # simple, detailed, expert

# Progressive disclosure settings
[diagnostics.progressive_disclosure]
auto_detect_user_level = true
default_level = "detailed"
enable_expansion = true

# AI integration settings
[diagnostics.ai]
enable_suggestion_generation = true
enable_educational_content = true
confidence_threshold = 0.7

# Performance settings
[diagnostics.performance]
enable_lazy_analysis = true
background_analysis_threads = 4
cache_size_mb = 100

# Integration settings
[diagnostics.integration]
enable_lsp_integration = true
enable_ide_code_actions = true
enable_ai_metadata_export = true
```

### Appendix C: Performance Benchmarks

```
Diagnostic Performance Targets:

Single Error Analysis:
- Simple errors: < 1ms
- Complex semantic errors: < 10ms  
- AI-enhanced analysis: < 50ms

Batch Analysis (1000 errors):
- Sequential: < 500ms
- Parallel: < 100ms

Memory Usage:
- Base diagnostic: < 1KB
- Enhanced diagnostic: < 5KB
- AI metadata: < 10KB

Cache Performance:
- Hit rate: > 85%
- Invalidation accuracy: > 99%
```

---

**Document Status**: Draft  
**Next Review**: 2025-01-24  
**Implementation Priority**: High (Phase 1) 